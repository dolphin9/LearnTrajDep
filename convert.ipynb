{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from os import walk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFileNames(Readpath:str) -> list:\n",
    "    files = []\n",
    "    for (dirpath, dirnames, filenames) in walk(Readpath):\n",
    "        files.extend(filenames)\n",
    "    print(f'read {len(files)} files ...')\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 209 files ...\n"
     ]
    }
   ],
   "source": [
    "moyoDataDir = './mosh/train/'\n",
    "files = readFileNames(moyoDataDir)\n",
    "moyotrain,moyotest = train_test_split(files,test_size=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files_in_folder(folder_path):    \n",
    "    # 遍历文件夹中的所有文件并删除\n",
    "    print(f'Start to delete files in {folder_path}')\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "                #print(f\"deleted file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"error when delete'{file_path}' : {e}\")\n",
    "    print(f'Delete {len(filename)} files succesfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertfiles(readPath: str, savePath: str, files: list): \n",
    "    if not os.path.exists(savePath):\n",
    "        os.makedirs(savePath)\n",
    "    else:\n",
    "        delete_files_in_folder(savePath)\n",
    "    \n",
    "    print(f'start load {len(files)} from {readPath} to {savePath} ...')\n",
    "    for filename in files:\n",
    "        with open(readPath+filename,'rb') as f:\n",
    "            #print(\"load data from {}\".format(f.name))\n",
    "            data = pkl.load(f)\n",
    "            joint_pos = data['body_pose']\n",
    "            global_orient = data['global_orient']\n",
    "            poses = np.concatenate((joint_pos,global_orient), axis = 1)\n",
    "            poses = np.array([poses])\n",
    "            with open(savePath+filename,'wb') as fo:\n",
    "                fo = pkl.dump({'poses':poses}, fo)\n",
    "    print(f'load files ok!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def splitMoyoData(readDir: str, saveDir: str, )->None:\n",
    "    print('Preparing Moyo Data...')\n",
    "    # train folder\n",
    "    readPath = readDir+ 'train/'\n",
    "    files = readFileNames(readPath)\n",
    "    moyotrain,moyotest = train_test_split(files,test_size=0.3,shuffle=True)\n",
    "    print('===============train===============')\n",
    "    savePath = saveDir+ 'train/'\n",
    "    convertfiles(readPath,savePath,moyotrain)\n",
    "    print('===============test================')\n",
    "    savePath = saveDir+ 'test/'\n",
    "    convertfiles(readPath,savePath,moyotest)\n",
    "    # val folder\n",
    "    print('===================================')\n",
    "    readPath = readDir+ 'val/'\n",
    "    files = readFileNames(readPath)\n",
    "    print('================val================')\n",
    "    savePath = saveDir+ 'validation/'\n",
    "    convertfiles(readPath,savePath,files)\n",
    "    print(f'Moyo Data prepared!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Moyo Data...\n",
      "read 299 files ...\n",
      "===============train===============\n",
      "Start to delet files in ./mosh/train/\n",
      "Delete 108 files succesfully!\n",
      "start load 209 from ./mosh_smpl/train/ to ./mosh/train/ ...\n",
      "load files ok!\n",
      "===============test================\n",
      "Start to delet files in ./mosh/test/\n",
      "Delete 97 files succesfully!\n",
      "start load 90 from ./mosh_smpl/train/ to ./mosh/test/ ...\n",
      "load files ok!\n",
      "===================================\n",
      "read 36 files ...\n",
      "================val================\n",
      "Start to delet files in ./mosh/validation/\n",
      "Delete 77 files succesfully!\n",
      "start load 36 from ./mosh_smpl/val/ to ./mosh/validation/ ...\n",
      "load files ok!\n",
      "Moyo Data prepared!\n"
     ]
    }
   ],
   "source": [
    "readPath = './dataset/mosh_smpl/'\n",
    "savePath = './dataset/mosh/'\n",
    "splitMoyoData(readPath,savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./dataset/mixed/\n",
    "!cp -r ./dataset/mosh/ ./dataset/mixed\n",
    "!cp -r ./dataset/3DPW/sequenceFiles/* ./dataset/mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_3dpw.py --data_dir_3dpw \"./dataset/mixed/\" --input_n 10 --output_n 30 --dct_n 40 --exp \"./logs/\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LTD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
